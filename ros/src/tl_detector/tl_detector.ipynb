{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic Light Detector Node CNN Experiments\n",
    "======\n",
    "\n",
    "These is the R&N notebook for the traffic light detector node\n",
    "The network is trained on 64x64 samples in 4 classes (nothing, red, green, yellow)\n",
    "\n",
    "Henrik TÃ¼nnermann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need to set the data path\n",
    "nothing = glob.glob(\"/home/kosuke/sf/data/traffic/nothing/*.jpg\")\n",
    "redlights = glob.glob(\"/home/kosuke/sf/data/traffic/redlights/*.jpg\")\n",
    "\n",
    "greenlights = glob.glob(\"/home/kosuke/sf/data/traffic/greenlights/*.jpg\")\n",
    "yellowlights = glob.glob(\"/home/kosuke/sf/data/traffic/yellowlights/*.jpg\")\n",
    "\n",
    "\n",
    "Y = np.concatenate([np.ones(len(redlights)), np.zeros(len(nothing))-1])\n",
    "Y = np.concatenate([np.array([[1,0,0,0]]*len(nothing)), \n",
    "                    np.array([[0,1,0,0]]*len(redlights)),\n",
    "                    np.array([[0,0,1,0]]*len(greenlights)),\n",
    "                    np.array([[0,0,0,1]]*len(yellowlights))\n",
    "                   ])\n",
    "\n",
    "# Read X Vector\n",
    "X = []\n",
    "for name in nothing:    \n",
    "    X.append(cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "for name in redlights:    \n",
    "    X.append(cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "for name in greenlights:    \n",
    "    X.append(cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "for name in yellowlights:    \n",
    "    X.append(cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline \n",
    "imshow(X[1255])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After loading I do the usual pre-processing\n",
    "\n",
    "I do not use a validation split, but I have to validate that the model works well in localization independently anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.10, random_state=42)\n",
    "\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "input_shape =  (3,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def model(data, train):\n",
    "    norm = data/127.5 - 1\n",
    "    c1 = tf.layers.conv2d(norm, 16, 3, strides=(1, 1), padding='SAME',\n",
    "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.001), activation=tf.nn.relu)\n",
    "    c2 = tf.layers.conv2d(c1, 16, 3, strides=(1, 1), padding='SAME',\n",
    "                            kernel_initializer=tf.truncated_normal_initializer(stddev=0.001), activation=tf.nn.relu)\n",
    "    p = tf.layers.max_pooling2d(c2, 8, strides=(8,8), padding='SAME')\n",
    "    \n",
    "    drop1 = tf.layers.dropout(p,rate=0.25,training=train)\n",
    "    \n",
    "    c3 = tf.layers.conv2d(drop1, 128, 8, strides=(1, 1), padding='VALID',\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.001), activation=tf.nn.relu)\n",
    "    \n",
    "    drop2 = tf.layers.dropout(c3,rate=0.50,training=train)\n",
    "    c4 = tf.layers.conv2d(drop2, 4, 1, strides=(1, 1), padding='VALID',\n",
    "        kernel_initializer=tf.truncated_normal_initializer(stddev=0.001))\n",
    "    sm = tf.nn.softmax(c4, name=\"output\")\n",
    "    return c4,sm\n",
    "    \n",
    "def loss(data, correct_label):    \n",
    "    logits = tf.reshape(data,(-1,4),name='logits')\n",
    "    labels = tf.reshape(correct_label,(-1,4),name='lables')\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "    tf_accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    return loss,train_op,tf_accuracy\n",
    "\n",
    "\n",
    "\n",
    "#need to set the test data path\n",
    "testdata = (cv2.cvtColor(cv2.imread(\"/home/kosuke/sf/data/testimagesreal/just00151.jpg\"), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "batches = (int(np.ceil(X_train.shape[0]/64.)))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    \n",
    "    tf_data = tf.placeholder(tf.float32, shape=(None, None, None, 3), name=\"image_input\")\n",
    "    tf_labels = tf.placeholder(tf.float32, shape=(None),name=\"labels_input\")\n",
    "    tf_train = tf.placeholder(tf.bool,name=\"train_input\")\n",
    "    \n",
    "    modelout,sm = model(tf_data, tf_train)\n",
    "    l,train_op, tf_accuracy = loss(modelout, tf_labels)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch_i in range(300):\n",
    "        for batch_i in range(batches):\n",
    "            train_loss, _, accuracy = sess.run([l, train_op, tf_accuracy],\n",
    "                        feed_dict={tf_data: X_train[batch_i*64:batch_i*64+64], \n",
    "                                   tf_labels: Y_train[batch_i*64:batch_i*64+64], \n",
    "                                   tf_train: True})\n",
    "            # Display the loss after every tenth batch\n",
    "            \n",
    "\n",
    "        # Display the loss after the epoch\n",
    "       \n",
    "        print('Epoch {:>3} Batch {:>2}   Training loss = {:.3f} Acc:{:.3f}'.format(epoch_i+1, batch_i+1, train_loss, accuracy))\n",
    "        \n",
    "        train_loss, accuracy = sess.run([l, tf_accuracy],feed_dict={tf_data: X_test, tf_labels: Y_test, \n",
    "                                   tf_train: False})\n",
    "        print('Test: Epoch {:>3} Batch {:>2}   Training loss = {:.3f} Acc:{:.3f}'.format(epoch_i+1, batch_i+1, train_loss, accuracy))\n",
    "        \n",
    "        \n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, \"tldetector.tf\",global_step=1000)\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "%pylab inline\n",
    "\n",
    "\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    saver = tf.train.import_meta_graph('tldetector.tf-1000.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    \n",
    "\n",
    "    tf_data = graph.get_tensor_by_name(\"image_input:0\")\n",
    "    tf_train = graph.get_tensor_by_name(\"train_input:0\")\n",
    "    tf_label = graph.get_tensor_by_name(\"labels_input:0\")    \n",
    "    sm = graph.get_tensor_by_name(\"output:0\")\n",
    "    \n",
    "    #green\n",
    "    testdata = (cv2.cvtColor(cv2.imread(\"/home/kosuke/sf/data/testimages/00745.jpg\"), cv2.COLOR_BGR2RGB))\n",
    "    #red\n",
    "    testdata = (cv2.cvtColor(cv2.imread(\"/home/kosuke/sf/data/testimages/00372.jpg\"), cv2.COLOR_BGR2RGB))\n",
    "    #on site yellow\n",
    "    testdata = (cv2.cvtColor(cv2.imread(\"/home/kosuke/sf/data/testimagesreal/just00134.jpg\"), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    \n",
    "    img = sess.run([sm], feed_dict={tf_data: testdata.reshape([1,300, 400, 3]), tf_train: False})\n",
    "    \n",
    "    threshold = 0.99\n",
    "    \n",
    "    img = np.array(img)\n",
    "    print(\"Nothing:\",np.sum(img[0,0,:,:,0]>threshold))\n",
    "    print(\"Red:\",np.sum(img[0,0,:,:,1]>threshold))\n",
    "    print(\"Green:\",np.sum(img[0,0,:,:,2]>threshold))\n",
    "    print(\"Yellow:\",np.sum(img[0,0,:,:,3]>threshold))\n",
    "    \n",
    "    \n",
    "    imshow(testdata)\n",
    "    show()\n",
    "    i = img[0,0,:,:,1]\n",
    "    \n",
    "    \n",
    "    imshow(i,vmin=0, vmax=1)\n",
    "    colorbar()\n",
    "    show()\n",
    "\n",
    "    def augment(raw,boolean, color):\n",
    "        xx, yy = np.meshgrid(np.arange(img.shape[3]),np.arange(img.shape[2]))\n",
    "\n",
    "        x = (xx[boolean])\n",
    "        y = (yy[boolean])\n",
    "\n",
    "        for i,j in zip(x,y):\n",
    "            cv2.rectangle(testdata, (i*8,j*8), (i*8+64,j*8+64), color, 5)\n",
    "            \n",
    "    augment(testdata,img[0,0,:,:,1]>threshold,(255,0,0))\n",
    "    augment(testdata,img[0,0,:,:,2]>threshold,(0,255,0))\n",
    "    augment(testdata,img[0,0,:,:,3]>threshold,(255,255,0))\n",
    "    \n",
    "    imshow(testdata)\n",
    "    show()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
